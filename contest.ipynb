{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c6f9c1-1b09-4e01-afdd-82e0b41b2753",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8da496-94d7-49a9-91f8-9096e890d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab718a-2da8-437c-9f56-d4d60bed4d09",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8effe668-4caf-4def-ac6b-5b08a4b03050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d6172-1f62-4085-be3c-ce8f0794bf93",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee0f647-a2bc-48db-a4ff-41fefb21f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATASET_PATH = 'data'\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "GLOBAL_MEAN, GLOBAL_STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "BATCH_SIZE = 128\n",
    "VAL_SIZE = .1\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6bd2a2-8301-486e-bad9-3126017cec88",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0e40e4-57c1-4f26-b5db-ce4e5c1358b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SportsDataset(Dataset):\n",
    "    def __init__(self, data_path, label2id, is_train=True, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.is_train = is_train\n",
    "        self.folder = join(data_path, 'train' if is_train else 'test')\n",
    "        self.images = listdir(self.folder)\n",
    "        self.dataframe = pd.read_csv(f'{self.folder}.csv')\n",
    "        self.label_encoding = encoder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.images[idx]\n",
    "        with Image.open(join(self.folder, image_name)).convert('RGB') as image:\n",
    "            image.load()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.is_train:\n",
    "            y = self.dataframe[self.dataframe.image_id == image_name].label.item()\n",
    "            return image, torch.from_numpy(self.label_encoding.transform([y])).type(torch.long)\n",
    "        return image, image_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4519ad9e-553d-4179-8ac7-c377bba8b1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = sorted(set(pd.read_csv(join(DATASET_PATH, 'train.csv')).label))\n",
    "NUM_CLASSES = len(unique_labels)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920b052a-f799-4392-9f81-a911c7cb0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(GLOBAL_MEAN, GLOBAL_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76fd0a70-08a3-4457-997e-228f0b20017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SportsDataset(DATASET_PATH, encoder, is_train=True, transform=transform)\n",
    "train_data, val_data = random_split(data, [1 - VAL_SIZE, VAL_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2466edd5-9f82-4174-8de5-aae8794c5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a9ccf-73a7-4ccb-9ded-27de3b7e6ca7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723fdbda-8fe7-4db1-bccd-e9023932e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = models.vit_l_32(weights='DEFAULT')\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model.heads = nn.Sequential(nn.Linear(1024, NUM_CLASSES))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d93c6c4-6bc4-4176-8b02-0885c402b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "Model                                                                  --\n",
       "├─VisionTransformer: 1-1                                               1,024\n",
       "│    └─Conv2d: 2-1                                                     (3,146,752)\n",
       "│    └─Encoder: 2-2                                                    51,200\n",
       "│    │    └─Dropout: 3-1                                               --\n",
       "│    │    └─Sequential: 3-2                                            (302,309,376)\n",
       "│    │    └─LayerNorm: 3-3                                             (2,048)\n",
       "│    └─Sequential: 2-3                                                 --\n",
       "│    │    └─Linear: 3-4                                                30,750\n",
       "===============================================================================================\n",
       "Total params: 305,541,150\n",
       "Trainable params: 30,750\n",
       "Non-trainable params: 305,510,400\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dff1d987-fb9a-4f88-9b98-b6de0ec89450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score\n",
    "micro_f1_score = F1Score(task=\"multiclass\", average=\"micro\", num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab13635b-4da5-49c8-92c1-b98dc37589f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=EPOCHS):\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_loss = val_loss = .0\n",
    "        true_labels, pred_labels = [], []\n",
    "        for X, y in tqdm(train_loader, leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).squeeze()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            true_labels.extend(y.cpu())\n",
    "            pred_labels.extend(outputs.cpu().argmax(1))\n",
    "            print(loss.item(), f1_score(true_labels, pred_labels, average='micro'))\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        f1_train = f1_score(true_labels, pred_labels, average='micro')\n",
    "        true_labels, pred_labels = [], []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in tqdm(val_loader, leave=False):\n",
    "                X = X.to(DEVICE)\n",
    "                y = y.to(DEVICE).squeeze()\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "                true_labels.extend(y.cpu())\n",
    "                pred_labels.extend(outputs.cpu().argmax(1))\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        f1_val = f1_score(true_labels, pred_labels, average='micro')\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1}, train loss: {train_loss:.4f},  val. loss: {val_loss:.4f},  f1_train: {f1_train},  f1_val: {f1_val}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708b588c-0a73-4008-bd00-5a258b99056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e04df-3f81-4b14-9efd-876ae730df06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d19b411b1d4dd2835fbd780d76684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4289536476135254 0.0390625\n",
      "3.4503109455108643 0.04296875\n",
      "3.361067056655884 0.041666666666666664\n",
      "3.4169652462005615 0.041015625\n",
      "3.4375741481781006 0.040625\n",
      "3.411011219024658 0.041666666666666664\n",
      "3.3752267360687256 0.04241071428571429\n",
      "3.383244514465332 0.046875\n",
      "3.4282023906707764 0.046875\n",
      "3.39577317237854 0.04609375\n",
      "3.424251079559326 0.04474431818181819\n",
      "3.369077444076538 0.046223958333333336\n",
      "3.4201738834381104 0.04807692307692308\n",
      "3.4292380809783936 0.04575892857142857\n",
      "3.3706068992614746 0.04791666666666667\n",
      "3.2952165603637695 0.05126953125\n",
      "3.3427724838256836 0.05193014705882354\n",
      "3.3242039680480957 0.055121527777777776\n",
      "3.3037900924682617 0.05879934210526316\n",
      "3.341883420944214 0.05859375\n",
      "3.307598829269409 0.06063988095238095\n",
      "3.3030197620391846 0.06321022727272728\n",
      "3.299844741821289 0.06657608695652174\n",
      "3.231071949005127 0.07063802083333333\n",
      "3.25761079788208 0.0703125\n",
      "3.2247300148010254 0.07271634615384616\n",
      "3.2371840476989746 0.07523148148148148\n",
      "3.2059414386749268 0.07784598214285714\n",
      "3.2298622131347656 0.07974137931034483\n",
      "3.242234706878662 0.08098958333333334\n",
      "3.1941964626312256 0.08341733870967742\n",
      "3.1718196868896484 0.086669921875\n",
      "3.173889636993408 0.08830492424242424\n",
      "3.166801691055298 0.09191176470588237\n",
      "3.155588150024414 0.09598214285714286\n",
      "3.108945608139038 0.099609375\n",
      "3.116873025894165 0.10282939189189189\n",
      "3.0521256923675537 0.10670230263157894\n",
      "3.113077163696289 0.10917467948717949\n",
      "3.106614351272583 0.1119140625\n",
      "3.082047700881958 0.11528201219512195\n",
      "3.1120071411132812 0.11867559523809523\n",
      "3.067068576812744 0.12154796511627906\n",
      "3.098358392715454 0.12482244318181818\n",
      "2.974290370941162 0.1310763888888889\n",
      "3.062051296234131 0.13400135869565216\n",
      "3.032384157180786 0.1371343085106383\n",
      "3.009554386138916 0.13916015625\n",
      "2.9616994857788086 0.14333545918367346\n",
      "3.0087194442749023 0.14671875\n",
      "3.0289885997772217 0.1485906862745098\n",
      "2.9362869262695312 0.15234375\n",
      "2.9479939937591553 0.15683962264150944\n",
      "3.038525104522705 0.1579861111111111\n",
      "2.944239854812622 0.16178977272727274\n",
      "2.9702632427215576 0.16462053571428573\n",
      "2.8661465644836426 0.1680372807017544\n",
      "2.9427125453948975 0.17174030172413793\n",
      "2.9055380821228027 0.1750529661016949\n",
      "2.9285311698913574 0.17760416666666667\n",
      "2.8653275966644287 0.18173668032786888\n",
      "2.8969931602478027 0.18460181451612903\n",
      "2.798379421234131 0.18799603174603177\n",
      "2.870210886001587 0.1910400390625\n",
      "2.8749630451202393 0.19254807692307693\n",
      "2.8197720050811768 0.1942471590909091\n",
      "2.9112656116485596 0.19566231343283583\n",
      "2.9402596950531006 0.1974954044117647\n",
      "2.9320645332336426 0.1995018115942029\n",
      "2.758249282836914 0.20290178571428572\n",
      "2.7847743034362793 0.20642605633802816\n",
      "2.8222150802612305 0.2082248263888889\n",
      "2.8489763736724854 0.2105094178082192\n",
      "2.808279275894165 0.21294341216216217\n",
      "2.7363831996917725 0.215625\n",
      "2.791020154953003 0.2178248355263158\n",
      "2.7268049716949463 0.2210836038961039\n",
      "2.727044105529785 0.22265625\n",
      "2.783928632736206 0.22517800632911392\n",
      "2.683734178543091 0.22744140625\n",
      "2.7009525299072266 0.22993827160493827\n",
      "2.6218044757843018 0.23266006097560976\n",
      "2.682727336883545 0.23597515060240964\n",
      "2.7844836711883545 0.23781622023809523\n",
      "2.636875867843628 0.24044117647058824\n",
      "2.5743560791015625 0.24400436046511628\n",
      "2.6116247177124023 0.2465876436781609\n",
      "2.671651840209961 0.24875710227272727\n",
      "2.675964832305908 0.25079002808988765\n",
      "2.6408469676971436 0.25286458333333334\n",
      "2.678614854812622 0.254635989010989\n",
      "2.613363265991211 0.2573879076086957\n",
      "2.6048033237457275 0.25982862903225806\n",
      "2.5988833904266357 0.2623005319148936\n",
      "2.6443264484405518 0.26348684210526313\n",
      "2.5352742671966553 0.2661946614583333\n",
      "2.517451286315918 0.2686050257731959\n",
      "2.505824327468872 0.27128507653061223\n",
      "2.481757164001465 0.273989898989899\n",
      "2.504910707473755 0.276328125\n",
      "2.5581820011138916 0.2784653465346535\n",
      "2.5600922107696533 0.27971813725490197\n",
      "2.4513533115386963 0.28178094660194175\n",
      "2.5365161895751953 0.2844801682692308\n",
      "2.503784418106079 0.2863095238095238\n",
      "2.505765676498413 0.2886939858490566\n",
      "2.4709956645965576 0.29066880841121495\n",
      "2.44319486618042 0.29311342592592593\n",
      "2.4835917949676514 0.29508314220183485\n",
      "2.4372665882110596 0.2969460227272727\n",
      "2.396270275115967 0.29877533783783783\n",
      "2.5062806606292725 0.30050223214285715\n",
      "2.5072543621063232 0.3018528761061947\n",
      "2.4000983238220215 0.30379660087719296\n",
      "2.4625256061553955 0.3052989130434783\n",
      "2.400883197784424 0.3071794181034483\n",
      "2.4952292442321777 0.30869391025641024\n",
      "2.496767282485962 0.3103151483050847\n",
      "2.5073351860046387 0.31138392857142855\n",
      "2.3113224506378174 0.3134765625\n",
      "2.4783575534820557 0.3146952479338843\n",
      "2.4061856269836426 0.3160860655737705\n",
      "2.4269356727600098 0.3173907520325203\n",
      "2.3634941577911377 0.31911542338709675\n",
      "2.342402219772339 0.32075\n",
      "2.4286839962005615 0.322234623015873\n",
      "2.3974318504333496 0.32381889763779526\n",
      "2.2772748470306396 0.3255615234375\n",
      "2.354750633239746 0.3270954457364341\n",
      "2.244475841522217 0.32884615384615384\n",
      "2.370993137359619 0.3302719465648855\n",
      "2.4212286472320557 0.3311434659090909\n",
      "2.334280252456665 0.3323543233082707\n",
      "2.29137921333313 0.3337803171641791\n",
      "2.2683210372924805 0.3355902777777778\n",
      "2.362924814224243 0.3366842830882353\n",
      "2.231585741043091 0.3378763686131387\n",
      "2.4682836532592773 0.3387115036231884\n",
      "2.3251099586486816 0.3400966726618705\n",
      "2.3315317630767822 0.3418526785714286\n",
      "2.221496820449829 0.3433067375886525\n",
      "2.2382099628448486 0.3449053697183099\n",
      "2.231062889099121 0.3468094405594406\n",
      "2.220639705657959 0.3481987847222222\n",
      "2.148244857788086 0.3500538793103448\n",
      "2.2701807022094727 0.3517230308219178\n",
      "2.343189239501953 0.35251913265306123\n",
      "2.294804096221924 0.35330447635135137\n",
      "2.206814765930176 0.35470847315436244\n",
      "2.2003395557403564 0.35604166666666665\n",
      "2.295093059539795 0.3568398178807947\n",
      "2.1927595138549805 0.358141447368421\n",
      "2.2492787837982178 0.359375\n",
      "2.300811290740967 0.3602374188311688\n",
      "2.176274538040161 0.36129032258064514\n",
      "2.1282880306243896 0.36242988782051283\n",
      "2.1763925552368164 0.36335589171974525\n",
      "2.2167305946350098 0.3645668512658227\n",
      "2.1454391479492188 0.3657625786163522\n",
      "2.278801679611206 0.366796875\n",
      "2.220064401626587 0.3677212732919255\n",
      "2.159506320953369 0.3688271604938272\n",
      "2.102541208267212 0.3700153374233129\n",
      "2.081815719604492 0.37123666158536583\n",
      "2.0691919326782227 0.37267992424242424\n",
      "2.025972843170166 0.37410579819277107\n",
      "2.109825611114502 0.37528068862275443\n",
      "2.040480136871338 0.37625558035714285\n",
      "2.064685106277466 0.37772744082840237\n",
      "2.1434314250946045 0.3786764705882353\n",
      "2.094944953918457 0.3797514619883041\n",
      "2.087855815887451 0.38063226744186046\n",
      "2.189002275466919 0.3814125722543353\n",
      "2.0892035961151123 0.38245330459770116\n",
      "2.0788636207580566 0.3834821428571429\n",
      "2.1903417110443115 0.38414417613636365\n",
      "2.0402369499206543 0.3851518361581921\n",
      "2.0634171962738037 0.38636762640449446\n",
      "2.135188341140747 0.38722067039106145\n",
      "2.007960081100464 0.3884548611111111\n",
      "2.094780921936035 0.38928694751381215\n",
      "2.165804624557495 0.39019574175824173\n",
      "2.0751867294311523 0.391051912568306\n",
      "1.8908452987670898 0.392578125\n",
      "2.0846729278564453 0.39353885135135136\n",
      "1.8771575689315796 0.3950352822580645\n",
      "2.161135673522949 0.39559659090909094\n",
      "2.0001628398895264 0.39640126329787234\n",
      "1.9689055681228638 0.3974454365079365\n",
      "1.9728120565414429 0.39847861842105264\n",
      "1.9489972591400146 0.3994600785340314\n",
      "2.0189261436462402 0.4006754557291667\n",
      "1.997788667678833 0.4013520077720207\n",
      "2.1910295486450195 0.4019007731958763\n",
      "2.027824878692627 0.4026442307692308\n",
      "1.920820713043213 0.4035395408163265\n",
      "2.082280158996582 0.40446541878172587\n",
      "2.083003044128418 0.40534248737373735\n",
      "1.9291154146194458 0.40625\n",
      "1.9386374950408936 0.407109375\n",
      "1.9078422784805298 0.408232276119403\n",
      "2.0075061321258545 0.4088412747524752\n",
      "2.0197346210479736 0.4095597290640394\n",
      "1.9446361064910889 0.4105392156862745\n",
      "1.9494988918304443 0.4111661585365854\n",
      "1.9261956214904785 0.41216626213592233\n",
      "2.0833089351654053 0.41285477053140096\n",
      "1.9482885599136353 0.41391225961538464\n",
      "2.0158393383026123 0.4146232057416268\n",
      "1.9428597688674927 0.4152901785714286\n",
      "1.9319452047348022 0.4162100118483412\n",
      "1.882226586341858 0.41693691037735847\n",
      "2.0446529388427734 0.4177303403755868\n",
      "1.878212809562683 0.41869889018691586\n",
      "1.9807076454162598 0.4194404069767442\n",
      "1.9301567077636719 0.42006655092592593\n",
      "1.8261889219284058 0.4209749423963134\n",
      "2.0234432220458984 0.42151662844036697\n",
      "1.9528522491455078 0.42205336757990874\n",
      "1.8540513515472412 0.4229403409090909\n",
      "1.9223268032073975 0.42350113122171945\n",
      "1.7263011932373047 0.42454954954954954\n",
      "1.7603133916854858 0.4255535313901345\n",
      "1.785988450050354 0.42647879464285715\n",
      "1.8469873666763306 0.4271875\n",
      "1.8609808683395386 0.4280627765486726\n",
      "1.8474416732788086 0.42893034140969155\n",
      "1.9883514642715454 0.42948190789473684\n",
      "1.8809103965759277 0.4300286572052402\n",
      "1.7899322509765625 0.43087635869565216\n",
      "1.7405191659927368 0.4317843614718615\n",
      "1.9213156700134277 0.4323814655172413\n",
      "1.892338752746582 0.4331075643776824\n",
      "1.9653525352478027 0.43359375\n",
      "1.9025593996047974 0.4341422872340426\n",
      "1.9903955459594727 0.4346861758474576\n",
      "1.7323180437088013 0.43548918776371304\n",
      "1.8628711700439453 0.43635110294117646\n",
      "1.8851462602615356 0.4369116108786611\n",
      "1.7484805583953857 0.43776041666666665\n",
      "1.8461284637451172 0.43837525933609955\n",
      "1.800107479095459 0.4392755681818182\n",
      "1.8900902271270752 0.4399755658436214\n",
      "1.8059159517288208 0.4406698258196722\n",
      "1.7418547868728638 0.4414859693877551\n",
      "1.7798782587051392 0.4421366869918699\n",
      "1.6369718313217163 0.4430351720647773\n",
      "1.967088222503662 0.4435483870967742\n",
      "1.709357738494873 0.44440261044176704\n",
      "1.8749430179595947 0.444875\n",
      "1.78127920627594 0.44553037848605576\n",
      "1.833562970161438 0.4459325396825397\n",
      "1.812888741493225 0.44651679841897235\n",
      "1.7745699882507324 0.4470656988188976\n",
      "1.7794582843780518 0.4478860294117647\n",
      "1.9237271547317505 0.448211669921875\n",
      "1.7016627788543701 0.4488995622568093\n",
      "1.8360214233398438 0.4494307170542636\n",
      "1.6071447134017944 0.45044039575289574\n",
      "1.6935127973556519 0.45126201923076925\n",
      "1.758594036102295 0.4518977490421456\n",
      "1.875313401222229 0.452349713740458\n",
      "1.959707260131836 0.4525308935361217\n",
      "1.7966341972351074 0.4529770359848485\n",
      "1.6913418769836426 0.45380306603773585\n",
      "1.8173069953918457 0.4543879229323308\n",
      "1.8879183530807495 0.45464653558052437\n",
      "1.7662699222564697 0.4552238805970149\n",
      "1.7111352682113647 0.4558550185873606\n",
      "1.7579456567764282 0.4563946759259259\n",
      "1.812628984451294 0.456815036900369\n",
      "1.7802218198776245 0.45751953125\n",
      "1.680445671081543 0.4582474816849817\n",
      "1.745200753211975 0.4586849908759124\n",
      "1.5868974924087524 0.4594602272727273\n",
      "1.7556817531585693 0.4600883152173913\n",
      "1.831079363822937 0.4605426444043321\n",
      "1.8334007263183594 0.46107801258992803\n",
      "1.7265483140945435 0.46174955197132617\n",
      "1.7811036109924316 0.4622767857142857\n",
      "1.6946114301681519 0.46299488434163705\n",
      "1.6880731582641602 0.4635693705673759\n",
      "1.7991074323654175 0.464139796819788\n",
      "1.6619305610656738 0.4647062059859155\n",
      "1.6526480913162231 0.4652412280701754\n",
      "1.6048355102539062 0.46593640734265734\n",
      "1.644730806350708 0.46651785714285715\n",
      "1.7616543769836426 0.4669325086805556\n",
      "1.709776520729065 0.46737132352941174\n",
      "1.7027606964111328 0.4679956896551724\n",
      "1.7514996528625488 0.4683741408934708\n",
      "1.6542022228240967 0.4689907962328767\n",
      "1.6529241800308228 0.46957657849829354\n",
      "1.6983932256698608 0.470078656462585\n",
      "1.7772102355957031 0.4703919491525424\n",
      "1.7626763582229614 0.4707295185810811\n",
      "1.5124176740646362 0.4714067760942761\n",
      "1.7859219312667847 0.4717648909395974\n",
      "1.612053394317627 0.4721989966555184\n",
      "1.8267050981521606 0.4724739583333334\n",
      "1.7333935499191284 0.4729028239202658\n",
      "1.7575552463531494 0.4734581953642384\n",
      "1.7989031076431274 0.47382941419141916\n",
      "1.6579318046569824 0.4742495888157895\n",
      "1.6557416915893555 0.4749487704918033\n",
      "1.6894186735153198 0.47549019607843135\n",
      "1.697664499282837 0.47587540716612375\n",
      "1.6213704347610474 0.47641030844155846\n",
      "1.8646584749221802 0.47661306634304207\n",
      "1.7052232027053833 0.4770665322580645\n",
      "1.5181804895401 0.47769292604501606\n",
      "1.632238745689392 0.47814002403846156\n",
      "1.7100838422775269 0.47860922523961663\n",
      "1.9519011974334717 0.4788515127388535\n",
      "1.636077880859375 0.47926587301587303\n",
      "1.6910834312438965 0.4797023338607595\n",
      "1.5770505666732788 0.48045642744479494\n",
      "1.5464091300964355 0.4808863993710692\n",
      "1.6998709440231323 0.48136265673981193\n",
      "2.391491413116455 0.4813399941228328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 0.0181,  val. loss: 0.0131,  f1_train: 0.4813399941228328,  f1_val: 0.6193519947101609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e9fbf60e5e4038943d3c18cb58a87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6674236059188843 0.640625\n",
      "1.6508842706680298 0.6328125\n",
      "1.616401195526123 0.6380208333333334\n",
      "1.7097362279891968 0.623046875\n",
      "1.5990649461746216 0.625\n",
      "1.7255960702896118 0.625\n",
      "1.680155634880066 0.6272321428571429\n",
      "1.5241961479187012 0.634765625\n",
      "1.5540003776550293 0.6362847222222222\n",
      "1.7205877304077148 0.6296875\n",
      "1.5005379915237427 0.6342329545454546\n",
      "1.5266265869140625 0.634765625\n",
      "1.6411280632019043 0.6298076923076923\n",
      "1.5499167442321777 0.6294642857142857\n",
      "1.5203136205673218 0.6296875\n",
      "1.7049176692962646 0.6259765625\n",
      "1.7164580821990967 0.6259191176470589\n",
      "1.5920592546463013 0.6267361111111112\n",
      "1.6074334383010864 0.6254111842105263\n",
      "1.5453574657440186 0.62734375\n",
      "1.5795789957046509 0.6272321428571429\n",
      "1.6345516443252563 0.6274857954545454\n",
      "1.5452998876571655 0.6311141304347826\n",
      "1.6627984046936035 0.6295572916666666\n",
      "1.58347749710083 0.6296875\n",
      "1.7906080484390259 0.6277043269230769\n",
      "1.5473134517669678 0.6304976851851852\n",
      "1.5600810050964355 0.6303013392857143\n",
      "1.4904361963272095 0.6306573275862069\n",
      "1.6125009059906006 0.6296875\n",
      "1.48600435256958 0.6300403225806451\n",
      "1.4403597116470337 0.632080078125\n",
      "1.6298444271087646 0.6323390151515151\n",
      "1.5725895166397095 0.6325827205882353\n",
      "1.5802979469299316 0.6319196428571429\n",
      "1.666904091835022 0.6321614583333334\n",
      "1.6798171997070312 0.6311233108108109\n",
      "1.6792694330215454 0.6309621710526315\n",
      "1.5355267524719238 0.6330128205128205\n",
      "1.671090841293335 0.631640625\n",
      "1.6186330318450928 0.6314786585365854\n",
      "1.4605333805084229 0.6328125\n",
      "1.7042527198791504 0.6317223837209303\n",
      "1.6775376796722412 0.6294389204545454\n",
      "1.5370466709136963 0.6300347222222222\n",
      "1.4008640050888062 0.6306046195652174\n",
      "1.6822736263275146 0.6294880319148937\n",
      "1.6418546438217163 0.6297200520833334\n",
      "1.4564082622528076 0.6308992346938775\n",
      "1.6944864988327026 0.630625\n",
      "1.4808790683746338 0.6306678921568627\n",
      "1.6160290241241455 0.6296574519230769\n",
      "1.598458170890808 0.629127358490566\n",
      "1.3938837051391602 0.6304976851851852\n",
      "1.3907405138015747 0.6319602272727273\n",
      "1.5849509239196777 0.6319754464285714\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285739e-62e0-4512-a8d2-d9122b1c2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(train_losses, label = 'train')\n",
    "plt.plot(val_losses, label = 'val')\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39683922-27f5-4dc4-b9b9-cc5dc3ce3362",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6c56f-062c-4ffb-b307-5db443a3767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = SportsDataset(DATASET_PATH, encoder, is_train=False, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5b031-0f54-4891-bf91-a3863896929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, test_loader, encoder, filename):\n",
    "    image_ids, labels = [], []\n",
    "    for X, y in tqdm(test_loader):\n",
    "        X = X.to(DEVICE)\n",
    "        image_ids.extend(y)\n",
    "        preds = model(X).cpu().argmax(1)\n",
    "        labels.extend(encoder.inverse_transform(preds))\n",
    "\n",
    "    predictions = pd.DataFrame({\"image_id\": image_ids, \"label\": labels})\n",
    "    predictions.to_csv(filename, index=False)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14615ed-4909-4cb5-aeb8-ca2dd2d61741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_prediction(model, test_loader, encoder, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
